Random Sampling
Training parameters: {'LOG_DIR': './logs', 'dataset': 'cub', 'sz_embedding': 384, 'sz_batch': 16, 'nb_epochs': 60, 'gpu_id': 0, 'nb_workers': 0, 'model': 'deit_small_distilled_patch16_224', 'loss': 'Proxy_Anchor', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 0.0001, 'lr_decay_step': 5, 'lr_decay_gamma': 0.5, 'alpha': 32, 'mrg': 0.1, 'IPC': None, 'warm': 0, 'bn_freeze': 0, 'l2_norm': 1, 'remark': '', 'readpath': ''}
Training for 60 epochs.



















































































































Train Epoch: 0 [549/551 (99%)] Loss: 20.330864: : 549it [03:52,  2.34it/s]
Train Epoch: 0 [551/551 (100%)] Loss: 19.526253: : 551it [03:53,  2.36it/s]











100%|██████████| 186/186 [00:22<00:00,  8.09it/s]
F1: 0.02910279040831913
NMI: 0.14632623802639744
recall@1: 0.037761294672960216
recall@2: 0.06540795684423466
recall@4: 0.12508428860418072
recall@8: 0.2198246797033041
MAP@R: 0.0033739037299517715
RP: 0.027177515636172787




















































































































Train Epoch: 1 [549/551 (99%)] Loss: 19.517479: : 549it [03:55,  2.34it/s]
Train Epoch: 1 [551/551 (100%)] Loss: 19.285971: : 551it [03:56,  2.33it/s]











100%|██████████| 186/186 [00:23<00:00,  8.07it/s]
F1: 0.023980739379731993
NMI: 0.13302660917471076
recall@1: 0.027646662171274445
recall@2: 0.049898853674983146
recall@4: 0.09406608226567768
recall@8: 0.1830748482805125
MAP@R: 0.0026506633689959095
RP: 0.02419820583919123



















































































































Train Epoch: 2 [550/551 (100%)] Loss: 20.307856: : 550it [03:53,  2.35it/s]
Train Epoch: 2 [551/551 (100%)] Loss: 19.884081: : 551it [03:53,  2.36it/s]











100%|██████████| 186/186 [00:23<00:00,  7.94it/s]
F1: 0.02448358889874541
NMI: 0.12810851963183
recall@1: 0.024275118004045852
recall@2: 0.050236008091706
recall@4: 0.10013486176668915
recall@8: 0.1861092380310182
MAP@R: 0.002601079756148611
RP: 0.02428941469790958

















































