
Train Epoch: 0 [2/97 (1%)] Loss: 28.204088: : 2it [00:01,  1.24it/s]
Random Sampling
Training parameters: {'LOG_DIR': './logs', 'dataset': 'cub', 'sz_embedding': 384, 'sz_batch': 60, 'nb_epochs': 60, 'gpu_id': 0, 'nb_workers': 0, 'model': 'deit_small_distilled_patch16_224', 'loss': 'Proxy_Anchor', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 0.0001, 'lr_decay_step': 5, 'lr_decay_gamma': 0.5, 'alpha': 32, 'mrg': 0.1, 'IPC': None, 'warm': 5, 'bn_freeze': 0, 'l2_norm': 1, 'remark': '', 'readpath': ''}



























Train Epoch: 0 [96/97 (98%)] Loss: 20.848688: : 96it [00:56,  1.69it/s]
Train Epoch: 0 [97/97 (99%)] Loss: 21.041775: : 97it [00:56,  1.70it/s]






















100%|██████████| 99/99 [02:10<00:00,  1.31s/it]
F1: 0.017858639621139094
NMI: 0.21987942599283694
recall@1: 0.027683997299122215
recall@2: 0.04827819041188386
recall@4: 0.08575286968264687
recall@8: 0.14821066846725187
MAP@R: 0.002179512076457459
