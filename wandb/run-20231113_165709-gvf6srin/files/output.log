Random Sampling
Training parameters: {'LOG_DIR': './logs', 'dataset': 'cub', 'sz_embedding': 384, 'sz_batch': 60, 'nb_epochs': 60, 'gpu_id': 0, 'nb_workers': 0, 'model': 'deit_small_distilled_patch16_224', 'loss': 'Proxy_Anchor', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 0.0001, 'lr_decay_step': 5, 'lr_decay_gamma': 0.5, 'alpha': 32, 'mrg': 0.1, 'IPC': None, 'warm': 5, 'bn_freeze': 0, 'l2_norm': 1, 'remark': '', 'readpath': ''}
Training for 60 epochs.






































Train Epoch: 0 [147/147 (99%)] Loss: 21.558752: : 147it [01:20,  1.83it/s]
  0%|          | 0/50 [00:00<?, ?it/s]











100%|██████████| 50/50 [00:20<00:00,  2.50it/s]
F1: 0.02834508908961471
NMI: 0.1492473890258675
recall@1: 0.034726904922454484
recall@2: 0.06136210384356035
recall@4: 0.12070128118678354
recall@8: 0.20498988536749832
MAP@R: 0.0032722194710446636
RP: 0.0274357371715941







































Train Epoch: 1 [146/147 (99%)] Loss: 21.371681: : 146it [01:19,  1.84it/s]
Train Epoch: 1 [147/147 (99%)] Loss: 21.276831: : 147it [01:19,  1.84it/s]









100%|██████████| 50/50 [00:19<00:00,  2.53it/s]
F1: 0.02834508908961471
NMI: 0.1492473890258675
recall@1: 0.034726904922454484
recall@2: 0.06136210384356035
recall@4: 0.12070128118678354
recall@8: 0.20498988536749832
MAP@R: 0.0032722194710446636
RP: 0.0274357371715941







































Train Epoch: 2 [145/147 (98%)] Loss: 21.832043: : 145it [01:19,  1.72it/s]
Train Epoch: 2 [147/147 (99%)] Loss: 22.361668: : 147it [01:20,  1.83it/s]










100%|██████████| 50/50 [00:19<00:00,  2.53it/s]
F1: 0.02834508908961471
NMI: 0.1492473890258675
recall@1: 0.034726904922454484
recall@2: 0.06136210384356035
recall@4: 0.12070128118678354
recall@8: 0.20498988536749832
MAP@R: 0.0032722194710446636
RP: 0.0274357371715941







































Train Epoch: 3 [146/147 (99%)] Loss: 21.863125: : 146it [01:19,  1.84it/s]
Train Epoch: 3 [147/147 (99%)] Loss: 21.863359: : 147it [01:20,  1.84it/s]










100%|██████████| 50/50 [00:19<00:00,  2.52it/s]
F1: 0.02834508908961471
NMI: 0.1492473890258675
recall@1: 0.034726904922454484
recall@2: 0.06136210384356035
recall@4: 0.12070128118678354
recall@8: 0.20498988536749832
MAP@R: 0.0032722194710446636
RP: 0.0274357371715941







































Train Epoch: 4 [147/147 (99%)] Loss: 21.406860: : 147it [01:21,  1.80it/s]
  2%|▏         | 1/50 [00:00<00:18,  2.59it/s]










100%|██████████| 50/50 [00:20<00:00,  2.47it/s]
F1: 0.02834508908961471
NMI: 0.1492473890258675
recall@1: 0.034726904922454484
recall@2: 0.06136210384356035
recall@4: 0.12070128118678354
recall@8: 0.20498988536749832
MAP@R: 0.0032722194710446636
RP: 0.0274357371715941



















































































































































Train Epoch: 5 [147/147 (99%)] Loss: 27.235229: : 147it [1:00:37, 24.74s/it]
**Evaluating...**












100%|██████████| 50/50 [00:24<00:00,  2.04it/s]
0it [00:00, ?it/s]
F1: 0.03010850826488186
NMI: 0.16364530611352018
recall@1: 0.030681051921780174
recall@2: 0.05933917734322319
recall@4: 0.10923803101820634
recall@8: 0.20465273095077546
MAP@R: 0.0033114263083324318



















































































































































Train Epoch: 6 [147/147 (99%)] Loss: 36.561569: : 147it [1:03:32, 25.94s/it]
**Evaluating...**












100%|██████████| 50/50 [00:23<00:00,  2.09it/s]
F1: 0.03145708968750755
NMI: 0.16121303139423804
recall@1: 0.03506405933917734
recall@2: 0.06979096426163182
recall@4: 0.13385030343897505
recall@8: 0.23263654753877275
MAP@R: 0.0037537485558307554
RP: 0.030309100562745914








































































